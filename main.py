import asyncio

import dotenv

dotenv.load_dotenv()  # noqa: E402

import sounddevice
from amazon_transcribe.client import TranscribeStreamingClient
from amazon_transcribe.handlers import TranscriptResultStreamHandler
from amazon_transcribe.model import TranscriptEvent, TranscriptResultStream
from src.config import config
from src.constant import SAMPLE_RATE, CHUNK_SIZE
from src.llm import BedrockLLM
from src.logger import logger

logger.info("ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ", config=config)


class MyEventHandler(TranscriptResultStreamHandler):
    def __init__(self, transcript_result_stream: TranscriptResultStream, llm: BedrockLLM):
        super().__init__(transcript_result_stream)
        self.llm = llm
        self.is_listening = False
        self.messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ì‚¬ìš©ìì˜ ì–¸ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.",
            }
        ]

    async def handle_transcript_event(self, transcript_event: TranscriptEvent):
        results = transcript_event.transcript.results

        # ìŒì„± ì¸ì‹ ì‹œì‘ ê°ì§€
        if results and not self.is_listening:
            logger.info("ğŸ¤ ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.is_listening = True

        # ìŒì„± ì¸ì‹ ì¢…ë£Œ ê°ì§€
        if not results and self.is_listening:
            logger.info("ğŸ”‡ ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.is_listening = False
            return

        for result in results:
            # ìŒì„± ì¸ì‹ ì¢…ë£Œ ê°ì§€ (ê²°ê³¼ê°€ ìµœì¢…ì¸ ê²½ìš°)
            if not result.is_partial and self.is_listening:
                self.is_listening = False
                logger.info("ğŸ”‡ ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

                user_input = result.alternatives[0].transcript
                logger.info(f"ğŸ”‡ ìŒì„± ì¸ì‹ ê²°ê³¼: {user_input}")

                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                self.messages.append({"role": "user", "content": user_input})

                # LLMì— ì „ì²´ ëŒ€í™” ê¸°ë¡ ì „ë‹¬
                response = await self.llm.model.ainvoke(self.messages)

                # AI ì‘ë‹µ ì¶”ê°€
                ai_response = response.content
                self.messages.append({"role": "assistant", "content": ai_response})

                logger.info(f"ğŸ¤– AI: {ai_response}")


async def mic_stream(sample_rate, chunk_size):
    # This function wraps the raw input stream from the microphone forwarding
    # the blocks to an asyncio.Queue.
    loop = asyncio.get_event_loop()
    input_queue = asyncio.Queue()

    def callback(indata, frame_count, time_info, status):
        loop.call_soon_threadsafe(input_queue.put_nowait, (bytes(indata), status))

    # Be sure to use the correct parameters for the audio stream that matches
    # the audio formats described for the source language you'll be using:
    # https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html
    stream = sounddevice.RawInputStream(
        channels=1,
        samplerate=sample_rate,
        callback=callback,
        blocksize=chunk_size,
        dtype="int16",
    )
    # Initiate the audio stream and asynchronously yield the audio chunks
    # as they become available.
    with stream:
        while True:
            indata, status = await input_queue.get()
            yield indata, status


async def write_chunks(stream):
    async for chunk, status in mic_stream(SAMPLE_RATE, CHUNK_SIZE):
        await stream.input_stream.send_audio_event(audio_chunk=chunk)
    await stream.input_stream.end_stream()


async def basic_transcribe(
    llm: BedrockLLM,
    sample_rate: int,
    lang_code: str,
):
    client = TranscribeStreamingClient(region=config.aws_default_region)

    stream = await client.start_stream_transcription(
        language_code=lang_code,
        media_sample_rate_hz=sample_rate,
        media_encoding="pcm",
    )

    logger.info("ğŸ™ï¸ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì±„ë„ì´ ì—´ë ¸ìŠµë‹ˆë‹¤. ë§ì”€í•´ ì£¼ì„¸ìš”.")

    # Instantiate our handler and start processing events
    handler = MyEventHandler(stream.output_stream, llm)
    await asyncio.gather(write_chunks(stream), handler.handle_events())


if __name__ == "__main__":
    # TODO: VAD ì¶”ê°€

    # LLM ì´ˆê¸°í™”
    llm = BedrockLLM(
        model_id="us.anthropic.claude-3-5-haiku-20241022-v1:0",
        aws_profile_name=config.aws_profile,
    )

    # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    try:
        loop.run_until_complete(
            basic_transcribe(
                llm=llm,
                sample_rate=SAMPLE_RATE,
                lang_code=config.lang_code,
            )
        )
    finally:
        loop.close()
