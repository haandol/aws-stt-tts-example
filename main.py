import asyncio
import numpy as np
import torch

import dotenv

dotenv.load_dotenv()  # noqa: E402

import sounddevice
from amazon_transcribe.client import TranscribeStreamingClient
from amazon_transcribe.handlers import TranscriptResultStreamHandler
from amazon_transcribe.model import TranscriptEvent, TranscriptResultStream

from silero_vad import load_silero_vad
from src.config import config
from src.constant import SAMPLE_RATE, CHUNK_SIZE
from src.llm import BedrockLLM
from src.tts import PollyTTS
from src.logger import logger

logger.info("ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ", config=config)

# VAD ëª¨ë¸ ì „ì—­ ë³€ìˆ˜
vad_model = None

# ìŒì„± ì…ë ¥ ìƒíƒœ ê´€ë¦¬
is_processing_response = False  # LLM ì²˜ë¦¬ ë° TTS ì¬ìƒ ì¤‘ì¸ì§€ ì—¬ë¶€


def initialize_vad():
    """VAD ëª¨ë¸ ì´ˆê¸°í™”"""
    global vad_model
    if vad_model is None:
        logger.info("ğŸ¯ Silero VAD ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
        vad_model = load_silero_vad()
        torch.set_num_threads(1)
        logger.info("âœ… Silero VAD ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return vad_model


def detect_voice_activity(audio_chunk, threshold=0.5):
    """
    ì˜¤ë””ì˜¤ ì²­í¬ì—ì„œ ìŒì„± í™œë™ì„ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        audio_chunk: 16-bit PCM ì˜¤ë””ì˜¤ ë°ì´í„°
        threshold: VAD ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0)

    Returns:
        bool: ìŒì„±ì´ ê°ì§€ë˜ë©´ True, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ False
    """
    try:
        # int16 PCM ë°ì´í„°ë¥¼ float32ë¡œ ë³€í™˜ (-1.0 ~ 1.0 ë²”ìœ„)
        audio_float = np.frombuffer(audio_chunk, dtype=np.int16).astype(np.float32) / 32768.0

        # VAD ëª¨ë¸ ì…ë ¥ì„ ìœ„í•´ torch tensorë¡œ ë³€í™˜
        audio_tensor = torch.from_numpy(audio_float)

        # VAD ì‹ ë¢°ë„ ê³„ì‚°
        speech_prob = vad_model(audio_tensor, SAMPLE_RATE).item()

        # ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ìŒì„±ìœ¼ë¡œ ê°„ì£¼
        return speech_prob > threshold

    except Exception as e:
        logger.warning(f"âš ï¸ VAD ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return True  # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ìŒì„±ìœ¼ë¡œ ê°„ì£¼


class MyEventHandler(TranscriptResultStreamHandler):
    def __init__(self, transcript_result_stream: TranscriptResultStream, llm: BedrockLLM, tts: PollyTTS):
        super().__init__(transcript_result_stream)
        self.llm = llm
        self.tts = tts
        self.is_listening = False
        self.voice_buffer = []  # ìŒì„± ë²„í¼
        self.silence_counter = 0  # ë¬´ìŒ ì¹´ìš´í„°
        self.silence_threshold = 30  # ë¬´ìŒ ì„ê³„ê°’ (ì•½ 1ì´ˆ = 30 * 32ms)
        self.min_speech_chunks = 5  # ìµœì†Œ ìŒì„± ì²­í¬ ìˆ˜
        self.messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ ì‚¬ìš©ìì˜ ì–¸ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.",
            }
        ]

    async def handle_transcript_event(self, transcript_event: TranscriptEvent):
        global is_processing_response

        # ì‘ë‹µ ì²˜ë¦¬ ì¤‘ì´ë©´ ìŒì„± ì¸ì‹ ë¬´ì‹œ
        if is_processing_response:
            return

        results = transcript_event.transcript.results

        # ìŒì„± ì¸ì‹ ì‹œì‘ ê°ì§€
        if results and not self.is_listening:
            logger.info("ğŸ¤ ìŒì„± ì¸ì‹ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.is_listening = True

        # ìŒì„± ì¸ì‹ ì¢…ë£Œ ê°ì§€
        if not results and self.is_listening:
            logger.info("ğŸ”‡ ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            self.is_listening = False
            return

        for result in results:
            # ìŒì„± ì¸ì‹ ì¢…ë£Œ ê°ì§€ (ê²°ê³¼ê°€ ìµœì¢…ì¸ ê²½ìš°)
            if not result.is_partial and self.is_listening:
                self.is_listening = False
                logger.info("ğŸ”‡ ìŒì„± ì¸ì‹ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

                user_input = result.alternatives[0].transcript
                logger.info(f"ğŸ”‡ ìŒì„± ì¸ì‹ ê²°ê³¼: {user_input}")

                # ì‘ë‹µ ì²˜ë¦¬ ì‹œì‘ - ë‹¤ìŒ ìŒì„± ì…ë ¥ ì°¨ë‹¨
                is_processing_response = True
                logger.info("â¸ï¸ ìŒì„± ì…ë ¥ì„ ì¼ì‹œ ì •ì§€í•©ë‹ˆë‹¤.")

                try:
                    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                    self.messages.append({"role": "user", "content": user_input})

                    # LLMì— ì „ì²´ ëŒ€í™” ê¸°ë¡ ì „ë‹¬
                    logger.info("ğŸ¤– LLM ì²˜ë¦¬ ì¤‘...")
                    response = await self.llm.model.ainvoke(self.messages)

                    # AI ì‘ë‹µ ì¶”ê°€
                    ai_response = response.content
                    self.messages.append({"role": "assistant", "content": ai_response})

                    logger.info(f"ğŸ¤– AI: {ai_response}")

                    # TTSë¡œ AI ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ì¬ìƒ (ì§€í˜œ ëª©ì†Œë¦¬ ì‚¬ìš©)
                    logger.info("ğŸ”Š ìŒì„± ì¬ìƒ ì‹œì‘...")
                    await self.tts.speak_async(ai_response, voice_id=config.voice_id)
                    logger.info("âœ… ìŒì„± ì¬ìƒ ì™„ë£Œ")

                finally:
                    # ì‘ë‹µ ì²˜ë¦¬ ì™„ë£Œ - ìŒì„± ì…ë ¥ ì¬ê°œ
                    is_processing_response = False
                    logger.info("â–¶ï¸ ìŒì„± ì…ë ¥ì„ ì¬ê°œí•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")


async def mic_stream_with_vad(sample_rate, chunk_size):
    """VADê°€ ì ìš©ëœ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼"""
    global is_processing_response

    loop = asyncio.get_event_loop()
    input_queue = asyncio.Queue()

    # VAD ëª¨ë¸ ì´ˆê¸°í™”
    initialize_vad()

    # ìŒì„± ìƒíƒœ ì¶”ì  ë³€ìˆ˜
    is_speaking = False
    silence_counter = 0
    silence_threshold = 30  # ì•½ 1ì´ˆê°„ ë¬´ìŒì´ë©´ ìŒì„± ì¢…ë£Œë¡œ ê°„ì£¼ (30 * 32ms)

    def callback(indata, frame_count, time_info, status):
        loop.call_soon_threadsafe(input_queue.put_nowait, (bytes(indata), status))

    stream = sounddevice.RawInputStream(
        channels=1,
        samplerate=sample_rate,
        callback=callback,
        blocksize=chunk_size,
        dtype="int16",
    )

    with stream:
        logger.info("ğŸ¯ VADê°€ í™œì„±í™”ëœ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        while True:
            indata, status = await input_queue.get()

            # ì‘ë‹µ ì²˜ë¦¬ ì¤‘ì´ë©´ ìŒì„± ë°ì´í„° ì „ì†¡í•˜ì§€ ì•ŠìŒ (ë‹¨, ë¬´ìŒ ë°ì´í„°ëŠ” ì „ì†¡í•˜ì—¬ ì—°ê²° ìœ ì§€)
            if is_processing_response:
                # ë¬´ìŒ ë°ì´í„°ë¡œ ì—°ê²° ìœ ì§€
                silence_data = bytes(len(indata))  # ë¬´ìŒ ë°ì´í„° ìƒì„±
                yield silence_data, status
                continue

            # VADë¡œ ìŒì„± í™œë™ ê°ì§€ (ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë” ë¯¼ê°í•˜ê²Œ)
            has_voice = detect_voice_activity(indata, threshold=0.3)

            if has_voice:
                if not is_speaking:
                    logger.info("ğŸ¤ ìŒì„± í™œë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    is_speaking = True
                silence_counter = 0
            else:
                if is_speaking:
                    silence_counter += 1
                    # ì§§ì€ ë¬´ìŒì€ í—ˆìš© (ë§í•˜ëŠ” ì¤‘ê°„ì˜ ì§§ì€ ë©ˆì¶¤)
                    if silence_counter >= silence_threshold:
                        logger.info("ğŸ”‡ ìŒì„± í™œë™ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        is_speaking = False
                        silence_counter = 0

            # ì‹¤ì œ ìŒì„± ë°ì´í„° ì „ì†¡
            yield indata, status


async def write_chunks(stream):
    async for chunk, status in mic_stream_with_vad(SAMPLE_RATE, CHUNK_SIZE):
        await stream.input_stream.send_audio_event(audio_chunk=chunk)
    await stream.input_stream.end_stream()


async def basic_transcribe(
    llm: BedrockLLM,
    tts: PollyTTS,
    sample_rate: int,
    lang_code: str,
):
    client = TranscribeStreamingClient(region=config.aws_default_region)

    stream = await client.start_stream_transcription(
        language_code=lang_code,
        media_sample_rate_hz=sample_rate,
        media_encoding="pcm",
    )

    logger.info("ğŸ™ï¸ VAD ê¸°ë°˜ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì±„ë„ì´ ì—´ë ¸ìŠµë‹ˆë‹¤.")
    logger.info("âœ¨ ì¤€ë¹„ ì™„ë£Œ! ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. (AI ì‘ë‹µ ì¤‘ì—ëŠ” ë‹¤ìŒ ì…ë ¥ì´ ëŒ€ê¸°ë©ë‹ˆë‹¤)")

    # Instantiate our handler and start processing events
    handler = MyEventHandler(stream.output_stream, llm, tts)
    await asyncio.gather(write_chunks(stream), handler.handle_events())


if __name__ == "__main__":
    # VAD ì´ˆê¸°í™”
    initialize_vad()
    logger.info("âœ… Silero VADê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # LLM ì´ˆê¸°í™”
    llm = BedrockLLM(
        model_id=config.model_id,
        aws_profile_name=config.aws_profile,
    )

    # TTS ì´ˆê¸°í™” (ì§€í˜œ ëª©ì†Œë¦¬ ì‚¬ìš©)
    tts = PollyTTS(aws_profile_name=config.aws_profile)

    # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    try:
        loop.run_until_complete(
            basic_transcribe(
                llm=llm,
                tts=tts,
                sample_rate=SAMPLE_RATE,
                lang_code=config.lang_code,
            )
        )
    finally:
        loop.close()
